---
title: "Analyse multidimensionnelle : MDS (Multidimensional Scaling)"
subtitle: "Cours de visualisation multidimensionnelle"
author: "Vadim L, Valentine J, Emilie N"
format:
  revealjs:
    theme: "serif"
    transition: fade
    slide-number: true
    center: true
    incremental: true
    mathjax: "default"
---

## Objectif du MDS

Multidimensional Scaling (MDS) À partir de mesures de dissimilarité entre paires d’objets, on cherche à reconstruire une carte qui préserve les distances entre les points.

On peut partir de toute mesure de dissimilarité (pas forcément une distance métrique).

La carte reconstruite fournit des coordonnées $x_i = (x_{i1}, x_{i2})$.

La distance naturelle est : $$
\|x_i - x_j\|_2
$$

exemple de sortie

## Famille de méthodes MDS

Le MDS n’est pas une seule méthode, mais une famille d’algorithmes visant à trouver une configuration optimale dans un espace de faible dimension (souvent $p = 2$).

Les principales méthodes :

-   MDS classique (Classical MDS)

-   MDS métrique (Metric MDS)

-   MDS non métrique (Non-metric MDS)

    Exemple perception des couleurs (PDF)

------------------------------------------------------------------------

## Distance, dissimilarité et similarité

Les notions de distance, dissimilarité et similarité (ou proximité) sont définies pour toute paire d’objets.

On peut se demander si les dissimilarités données sont **vraiment des distances**, et si elles peuvent être **interprétées comme des distances euclidiennes**.

Étant donnée une matrice de dissimilarités $ D = (d_{ij}) $, le MDS cherche à trouver des points $ x_i,...x_n $ appartenant à $\mathbb{R}^p$.

tels que : $$
d_{ij} \approx \|x_i - x_j\|_2
$$

Si la configuration exacte existe → distance euclidienne\
Sinon → distance non euclidienne

------------------------------------------------------------------------

## Exemple de distance non euclidienne

La distance radiale sur un cercle (longueur de l’arc entre deux points) :

Est bien une métrique,\
Mais ne peut pas être représentée exactement dans un espace euclidien $\mathbb{R}^p$.

Le MDS cherche une configuration approchée minimisant l’écart entre $d_{ij}$ et $\|x_i - x_j\|_2$.

Photo exemple dans pdf FR

------------------------------------------------------------------------

## MDS classique : idée générale

But : retrouver les coordonnées des points à partir d’une matrice de distances $D = (d_{ij})$ supposées euclidiennes.

$$
\|x_i - x_j\| \approx d_{ij}
$$

Plutôt que de calculer $X$ directement, on travaille avec la matrice de produits scalaires : $$
B = X X'
$$

Si $X$ est centrée : $$
B = -\frac{1}{2} C D_2 C
$$ où \$ C \$est la matrice de centrage.

------------------------------------------------------------------------

## Étapes du calcul

Données d’entrée : la matrice des distances $D = (d_{ij})$.

Centrage double : $$
B = -\frac{1}{2} C D_2 C
$$

Décomposition en valeurs propres : $$
B = V \Lambda V'
$$

Coordonnées finales : $$
X = V \Lambda^{1/2}
$$

*Exemple:*\
**Distances → Matrice B → Décomposition → Coordonnées (R²)**

------------------------------------------------------------------------

## Réduction des dimensions

Souvent, on garde seulement les $p$ premières composantes correspondant aux plus grandes valeurs propres : $$
X^{(p)} = V_p \Lambda_p^{1/2}
$$ où :\
- $\Lambda_p$ = sous-matrice $(p \times p)$ des plus grandes valeurs propres\
- $V_p$ = les colonnes associées de $V$

Les colonnes de $X^{(p)}$ sont les axes principaux (comme en ACP).\
On obtient une carte 2D/3D qui préserve au mieux les distances.

------------------------------------------------------------------------

## Résumé : MDS classique

-   Conserve les distances euclidiennes autant que possible

-   Produit des coordonnées centrées et ordonnées par importance (variance)

-   Permet une visualisation claire des relations entre objets

-   Proche de l’ACP, mais part d’une matrice de distances.

    Voir les 3 exemples pdf

------------------------------------------------------------------------

## Distance Scaling (mise à l’échelle des distances)

Le MDS classique cherche une configuration $x_i$ telle que : $$
d_{ij} \approx \hat{d}_{ij} = \|x_i - x_j\|_2
$$

La mise à l’échelle des distances assouplit cette contrainte en autorisant une transformation monotone : $$
\hat{d}_{ij} \approx f(d_{ij})
$$ où $f$ est une fonction monotone croissante.

------------------------------------------------------------------------

## Types de MDS

-   **MDS métrique** : les dissimilarités $d_{ij}$ sont quantitatives
-   **MDS non métrique** : les dissimilarités $d_{ij}$ sont ordinales ou qualitatives

Différence avec le MDS classique :\
Contrairement au cMDS, la mise à l’échelle des distances est un processus d’optimisation.\
On cherche à minimiser une **fonction de stress**, et la solution est obtenue par des **algorithmes itératifs**.

------------------------------------------------------------------------

## MDS métrique

Le MDS métrique (ou *metric MDS*) cherche une configuration optimale $X \subset \mathbb{R}^p$ et une fonction monotone $f$ telles que : $$
f(d_{ij}) \approx \hat{d}_{ij} = \|x_i - x_j\|_2
$$

------------------------------------------------------------------------

## Fonction monotone et stress

$f$ peut être une fonction monotone paramétrique, par exemple : $$
f(d_{ij}) = \alpha + \beta d_{ij}
$$

La fonction de stress est : $$
\text{Stress} =
\left(
\frac{
\sum_{i<j} (\hat{d}_{ij} - f(d_{ij}))^2
}{
\sum d_{ij}^2
}
\right)^{1/2}
$$

Le MDS métrique minimise cette fonction sur $\hat{d}_{ij}, \alpha, \beta$.\
Le cas particulier $f(d_{ij}) = d_{ij}$ correspond au MDS classique.

------------------------------------------------------------------------

## Cartographie de Sammon (Sammon Mapping)

La **cartographie de Sammon** est une **généralisation du MDS métrique**.

La fonction de stress de Sammon est : $$
\text{Stress}_{\text{Sammon}} =
\frac{1}{\sum_{l<k} d_{lk}}
\sum_{i<j}
\frac{(\hat{d}_{ij} - d_{ij})^2}{d_{ij}}
$$

Les erreurs sont pondérées par $d_{ij}$, la distance d'origine, les petites distances on plus de poids ce qui : - préserve mieux les voisinages locaux, - donne une carte plus fidèle aux structures fines des données.

-   En conséquence, le Sammon mapping préserve les petits dij , leur accordant

    une plus grande importance dans la procédure d’ajustement que pour les valeurs plus élevées de dij

------------------------------------------------------------------------

## Comparaison : cMDS vs Sammon Mapping

| Méthode | Type | Objectif | Avantage principal |
|----|----|----|----|
| cMDS | Analytique | Préserver distances euclidiennes | Rapide, simple |
| Sammon Mapping | Numérique | Pondérer les erreurs par distance | Meilleure préservation locale |

------------------------------------------------------------------------

## MDS non métrique

Dans de nombreuses applications, les dissimilarités ne sont connues que par leur ordre de classement.

Le MDS non métrique cherche une configuration $X \subset \mathbb{R}^p$ telle que : $$
f(d_{ij}) \approx \hat{d}_{ij} = \|x_i - x_j\|_2
$$

On cherche uniquement à préserver l’ordre des dissimilarités : $$
d_{ij} < d_{kl} \iff f(d_{ij}) \le f(d_{kl}) \iff d_{ij}^* \le d_{kl}^*
$$

Les valeurs $d_{ij}^* = f(d_{ij})$ sont appelées **disparités**.\
Le MDS non métrique est donc basé sur les **rangs** plutôt que sur les valeurs absolues.

------------------------------------------------------------------------

## MDS non métrique de Kruskal

Kruskal (1964) propose de minimiser la fonction : $$
\text{Stress-1}(\hat{d}_{ij}, d_{ij}^*) =
\left(
\frac{
\sum_{i<j} (\hat{d}_{ij} - d_{ij}^*)^2
}{
\sum \hat{d}_{ij}^2
}
\right)^{1/2}
$$

Les dissimilarités initiales servent seulement à comparer les ordres :\
$d_{ij} < d_{kl} < ... < d_{mn}$

$f$ agit comme une régression monotone entre dissimilarités et distances.

------------------------------------------------------------------------

## Exemple : reconnaissance de lettres

Construction des dissimilarités à partir d’une matrice de similarité $\delta_{ij}$ : $$
d_{ij} =
\begin{cases}
c - \delta_{ij}, & \text{si } i \neq j \\
0, & \text{si } i = j
\end{cases}
$$ avec $c \ge \max(\delta_{ij})$.

------------------------------------------------------------------------

## Choix de la méthode

Comme les dissimilarités $d_{ij}$ dépendent du choix arbitraire de $c$,\
le MDS non métrique est souvent plus logique ici.\
Cependant, les méthodes métriques (cMDS, Sammon) peuvent aussi donner de bons résultats.
